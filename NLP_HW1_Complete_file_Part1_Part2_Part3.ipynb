{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.5"
    },
    "colab": {
      "name": "NLP_HW1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "t-IQThGcFz9x"
      },
      "source": [
        "import nltk\n",
        "import lxml\n",
        "from urllib.request import urlopen,urlretrieve\n",
        "from urllib.error import URLError\n",
        "from zipfile import ZipFile\n",
        "from bs4 import BeautifulSoup\n",
        "import gzip\n",
        "import shutil\n",
        "import xml.etree.ElementTree as ET\n",
        "from lxml import etree\n",
        "import os, zipfile\n",
        "import collections\n",
        "import pickle"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "c_v7YJmS4gzr",
        "outputId": "4e2d336b-bcc4-41fc-9665-483c658797dd"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FyvNs6t6Fz99"
      },
      "source": [
        "def download_xml_files(url,page,newdir,extension):\n",
        "  #Use BeautifulSoup to clean up the page\n",
        "  try:\n",
        "      shutil.rmtree(newdir)\n",
        "  except:\n",
        "      print(\"error in deleting\")\n",
        "  os.mkdir( newdir)                                  \n",
        "  soup = BeautifulSoup(page)\n",
        "  for anchor in soup.findAll('a', href=True):\n",
        "      links = url + anchor['href']\n",
        "      if links.endswith(extension):\n",
        "          ziplink = links\n",
        "          zipfile = links[67:]\n",
        "          zipfile2 = zipfile[:-3]\n",
        "          response = urlopen(ziplink)\n",
        "          zipcontent = response.read()\n",
        "          completeName = os.path.join(newdir, zipfile2+ extension)\n",
        "          with open (completeName, 'wb') as f:\n",
        "              print(\"downloading.. \" + zipfile)\n",
        "              f.write(zipcontent)\n",
        "              print(f)\n",
        "              f.close()"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uT1qXDR5Fz9-"
      },
      "source": [
        "# Unzip files:,\r\n",
        "def extract_content(newdir,extension):\r\n",
        "  cwd=os.getcwd()\r\n",
        "  newfile=cwd+\"/\"+\"deserialized.txt\"\r\n",
        "  if os.path.exists(newfile):\r\n",
        "    os.remove(newfile)\r\n",
        "  else:\r\n",
        "    print(\"The file does not exist\")\r\n",
        "  for item in os.listdir(newdir): # loop through items in dir,\r\n",
        "      if item.endswith(extension): # check for \\.zip\\ extension,\r\n",
        "          print(\"file name\",item)\r\n",
        "          file_name = newdir + \"/\" + item\r\n",
        "          f = gzip.open(file_name, 'rb')\r\n",
        "          tree = ET.parse(f)\r\n",
        "          root = tree.getroot()\r\n",
        "          for node in root.iter('DOC'):\r\n",
        "            for key,value in node.attrib.items():\r\n",
        "              if value=='story':\r\n",
        "                for elem in node.iter('TEXT'):\r\n",
        "                  for ele in elem.iter():\r\n",
        "                    if not ele.tag==elem.tag:\r\n",
        "                      with open(newfile,\"a+\") as output:\r\n",
        "                        output.write(str(ele.text)+ \"\\n\")"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TBTYitHd0uZH"
      },
      "source": [
        "url='https://cslu.ohsu.edu/~bedricks/courses/cs662/resources/GW-cna_eng/'\r\n",
        "page = urlopen('https://cslu.ohsu.edu/~bedricks/courses/cs662/resources/GW-cna_eng/').read() \r\n",
        "newdir=\"/content/drive/MyDrive/Colab Notebooks\"+\"/cna_eng\"\r\n",
        "extension=\".gz\""
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "6T1zH_CJrbEU",
        "outputId": "291aeffa-fe95-4e20-d706-8ff3f15ab063"
      },
      "source": [
        "\r\n",
        "download_xml_files(url,page,newdir,extension)\r\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "downloading.. cna_eng_199710.xml.gz\n",
            "<_io.BufferedWriter name='/content/drive/MyDrive/Colab Notebooks/cna_eng/cna_eng_199710.xml.gz'>\n",
            "downloading.. cna_eng_199712.xml.gz\n",
            "<_io.BufferedWriter name='/content/drive/MyDrive/Colab Notebooks/cna_eng/cna_eng_199712.xml.gz'>\n",
            "downloading.. cna_eng_199802.xml.gz\n",
            "<_io.BufferedWriter name='/content/drive/MyDrive/Colab Notebooks/cna_eng/cna_eng_199802.xml.gz'>\n",
            "downloading.. cna_eng_199804.xml.gz\n",
            "<_io.BufferedWriter name='/content/drive/MyDrive/Colab Notebooks/cna_eng/cna_eng_199804.xml.gz'>\n",
            "downloading.. cna_eng_199806.xml.gz\n",
            "<_io.BufferedWriter name='/content/drive/MyDrive/Colab Notebooks/cna_eng/cna_eng_199806.xml.gz'>\n",
            "downloading.. cna_eng_199808.xml.gz\n",
            "<_io.BufferedWriter name='/content/drive/MyDrive/Colab Notebooks/cna_eng/cna_eng_199808.xml.gz'>\n",
            "downloading.. cna_eng_199810.xml.gz\n",
            "<_io.BufferedWriter name='/content/drive/MyDrive/Colab Notebooks/cna_eng/cna_eng_199810.xml.gz'>\n",
            "downloading.. cna_eng_199812.xml.gz\n",
            "<_io.BufferedWriter name='/content/drive/MyDrive/Colab Notebooks/cna_eng/cna_eng_199812.xml.gz'>\n",
            "downloading.. cna_eng_199902.xml.gz\n",
            "<_io.BufferedWriter name='/content/drive/MyDrive/Colab Notebooks/cna_eng/cna_eng_199902.xml.gz'>\n",
            "downloading.. cna_eng_199904.xml.gz\n",
            "<_io.BufferedWriter name='/content/drive/MyDrive/Colab Notebooks/cna_eng/cna_eng_199904.xml.gz'>\n",
            "downloading.. cna_eng_199906.xml.gz\n",
            "<_io.BufferedWriter name='/content/drive/MyDrive/Colab Notebooks/cna_eng/cna_eng_199906.xml.gz'>\n",
            "downloading.. cna_eng_199908.xml.gz\n",
            "<_io.BufferedWriter name='/content/drive/MyDrive/Colab Notebooks/cna_eng/cna_eng_199908.xml.gz'>\n",
            "downloading.. cna_eng_199910.xml.gz\n",
            "<_io.BufferedWriter name='/content/drive/MyDrive/Colab Notebooks/cna_eng/cna_eng_199910.xml.gz'>\n",
            "downloading.. cna_eng_199912.xml.gz\n",
            "<_io.BufferedWriter name='/content/drive/MyDrive/Colab Notebooks/cna_eng/cna_eng_199912.xml.gz'>\n",
            "downloading.. cna_eng_200002.xml.gz\n",
            "<_io.BufferedWriter name='/content/drive/MyDrive/Colab Notebooks/cna_eng/cna_eng_200002.xml.gz'>\n",
            "downloading.. cna_eng_200004.xml.gz\n",
            "<_io.BufferedWriter name='/content/drive/MyDrive/Colab Notebooks/cna_eng/cna_eng_200004.xml.gz'>\n",
            "downloading.. cna_eng_200006.xml.gz\n",
            "<_io.BufferedWriter name='/content/drive/MyDrive/Colab Notebooks/cna_eng/cna_eng_200006.xml.gz'>\n",
            "downloading.. cna_eng_200008.xml.gz\n",
            "<_io.BufferedWriter name='/content/drive/MyDrive/Colab Notebooks/cna_eng/cna_eng_200008.xml.gz'>\n",
            "downloading.. cna_eng_200010.xml.gz\n",
            "<_io.BufferedWriter name='/content/drive/MyDrive/Colab Notebooks/cna_eng/cna_eng_200010.xml.gz'>\n",
            "downloading.. cna_eng_200012.xml.gz\n",
            "<_io.BufferedWriter name='/content/drive/MyDrive/Colab Notebooks/cna_eng/cna_eng_200012.xml.gz'>\n",
            "downloading.. cna_eng_200102.xml.gz\n",
            "<_io.BufferedWriter name='/content/drive/MyDrive/Colab Notebooks/cna_eng/cna_eng_200102.xml.gz'>\n",
            "downloading.. cna_eng_200104.xml.gz\n",
            "<_io.BufferedWriter name='/content/drive/MyDrive/Colab Notebooks/cna_eng/cna_eng_200104.xml.gz'>\n",
            "downloading.. cna_eng_200106.xml.gz\n",
            "<_io.BufferedWriter name='/content/drive/MyDrive/Colab Notebooks/cna_eng/cna_eng_200106.xml.gz'>\n",
            "downloading.. cna_eng_200108.xml.gz\n",
            "<_io.BufferedWriter name='/content/drive/MyDrive/Colab Notebooks/cna_eng/cna_eng_200108.xml.gz'>\n",
            "downloading.. cna_eng_200110.xml.gz\n",
            "<_io.BufferedWriter name='/content/drive/MyDrive/Colab Notebooks/cna_eng/cna_eng_200110.xml.gz'>\n",
            "downloading.. cna_eng_200112.xml.gz\n",
            "<_io.BufferedWriter name='/content/drive/MyDrive/Colab Notebooks/cna_eng/cna_eng_200112.xml.gz'>\n",
            "downloading.. cna_eng_200202.xml.gz\n",
            "<_io.BufferedWriter name='/content/drive/MyDrive/Colab Notebooks/cna_eng/cna_eng_200202.xml.gz'>\n",
            "downloading.. cna_eng_200308.xml.gz\n",
            "<_io.BufferedWriter name='/content/drive/MyDrive/Colab Notebooks/cna_eng/cna_eng_200308.xml.gz'>\n",
            "downloading.. cna_eng_200310.xml.gz\n",
            "<_io.BufferedWriter name='/content/drive/MyDrive/Colab Notebooks/cna_eng/cna_eng_200310.xml.gz'>\n",
            "downloading.. cna_eng_200312.xml.gz\n",
            "<_io.BufferedWriter name='/content/drive/MyDrive/Colab Notebooks/cna_eng/cna_eng_200312.xml.gz'>\n",
            "downloading.. cna_eng_200402.xml.gz\n",
            "<_io.BufferedWriter name='/content/drive/MyDrive/Colab Notebooks/cna_eng/cna_eng_200402.xml.gz'>\n",
            "downloading.. cna_eng_200404.xml.gz\n",
            "<_io.BufferedWriter name='/content/drive/MyDrive/Colab Notebooks/cna_eng/cna_eng_200404.xml.gz'>\n",
            "downloading.. cna_eng_200406.xml.gz\n",
            "<_io.BufferedWriter name='/content/drive/MyDrive/Colab Notebooks/cna_eng/cna_eng_200406.xml.gz'>\n",
            "downloading.. cna_eng_200408.xml.gz\n",
            "<_io.BufferedWriter name='/content/drive/MyDrive/Colab Notebooks/cna_eng/cna_eng_200408.xml.gz'>\n",
            "downloading.. cna_eng_200410.xml.gz\n",
            "<_io.BufferedWriter name='/content/drive/MyDrive/Colab Notebooks/cna_eng/cna_eng_200410.xml.gz'>\n",
            "downloading.. cna_eng_200412.xml.gz\n",
            "<_io.BufferedWriter name='/content/drive/MyDrive/Colab Notebooks/cna_eng/cna_eng_200412.xml.gz'>\n",
            "downloading.. cna_eng_200502.xml.gz\n",
            "<_io.BufferedWriter name='/content/drive/MyDrive/Colab Notebooks/cna_eng/cna_eng_200502.xml.gz'>\n",
            "downloading.. cna_eng_200504.xml.gz\n",
            "<_io.BufferedWriter name='/content/drive/MyDrive/Colab Notebooks/cna_eng/cna_eng_200504.xml.gz'>\n",
            "downloading.. cna_eng_200506.xml.gz\n",
            "<_io.BufferedWriter name='/content/drive/MyDrive/Colab Notebooks/cna_eng/cna_eng_200506.xml.gz'>\n",
            "downloading.. cna_eng_200508.xml.gz\n",
            "<_io.BufferedWriter name='/content/drive/MyDrive/Colab Notebooks/cna_eng/cna_eng_200508.xml.gz'>\n",
            "downloading.. cna_eng_200510.xml.gz\n",
            "<_io.BufferedWriter name='/content/drive/MyDrive/Colab Notebooks/cna_eng/cna_eng_200510.xml.gz'>\n",
            "downloading.. cna_eng_200512.xml.gz\n",
            "<_io.BufferedWriter name='/content/drive/MyDrive/Colab Notebooks/cna_eng/cna_eng_200512.xml.gz'>\n",
            "downloading.. cna_eng_200602.xml.gz\n",
            "<_io.BufferedWriter name='/content/drive/MyDrive/Colab Notebooks/cna_eng/cna_eng_200602.xml.gz'>\n",
            "downloading.. cna_eng_200604.xml.gz\n",
            "<_io.BufferedWriter name='/content/drive/MyDrive/Colab Notebooks/cna_eng/cna_eng_200604.xml.gz'>\n",
            "downloading.. cna_eng_200606.xml.gz\n",
            "<_io.BufferedWriter name='/content/drive/MyDrive/Colab Notebooks/cna_eng/cna_eng_200606.xml.gz'>\n",
            "downloading.. cna_eng_200608.xml.gz\n",
            "<_io.BufferedWriter name='/content/drive/MyDrive/Colab Notebooks/cna_eng/cna_eng_200608.xml.gz'>\n",
            "downloading.. cna_eng_200610.xml.gz\n",
            "<_io.BufferedWriter name='/content/drive/MyDrive/Colab Notebooks/cna_eng/cna_eng_200610.xml.gz'>\n",
            "downloading.. cna_eng_200612.xml.gz\n",
            "<_io.BufferedWriter name='/content/drive/MyDrive/Colab Notebooks/cna_eng/cna_eng_200612.xml.gz'>\n",
            "downloading.. cna_eng_200702.xml.gz\n",
            "<_io.BufferedWriter name='/content/drive/MyDrive/Colab Notebooks/cna_eng/cna_eng_200702.xml.gz'>\n",
            "downloading.. cna_eng_200704.xml.gz\n",
            "<_io.BufferedWriter name='/content/drive/MyDrive/Colab Notebooks/cna_eng/cna_eng_200704.xml.gz'>\n",
            "downloading.. cna_eng_200706.xml.gz\n",
            "<_io.BufferedWriter name='/content/drive/MyDrive/Colab Notebooks/cna_eng/cna_eng_200706.xml.gz'>\n",
            "downloading.. cna_eng_200708.xml.gz\n",
            "<_io.BufferedWriter name='/content/drive/MyDrive/Colab Notebooks/cna_eng/cna_eng_200708.xml.gz'>\n",
            "downloading.. cna_eng_200710.xml.gz\n",
            "<_io.BufferedWriter name='/content/drive/MyDrive/Colab Notebooks/cna_eng/cna_eng_200710.xml.gz'>\n",
            "downloading.. cna_eng_200712.xml.gz\n",
            "<_io.BufferedWriter name='/content/drive/MyDrive/Colab Notebooks/cna_eng/cna_eng_200712.xml.gz'>\n",
            "downloading.. cna_eng_200802.xml.gz\n",
            "<_io.BufferedWriter name='/content/drive/MyDrive/Colab Notebooks/cna_eng/cna_eng_200802.xml.gz'>\n",
            "downloading.. cna_eng_200804.xml.gz\n",
            "<_io.BufferedWriter name='/content/drive/MyDrive/Colab Notebooks/cna_eng/cna_eng_200804.xml.gz'>\n",
            "downloading.. cna_eng_200806.xml.gz\n",
            "<_io.BufferedWriter name='/content/drive/MyDrive/Colab Notebooks/cna_eng/cna_eng_200806.xml.gz'>\n",
            "downloading.. cna_eng_200808.xml.gz\n",
            "<_io.BufferedWriter name='/content/drive/MyDrive/Colab Notebooks/cna_eng/cna_eng_200808.xml.gz'>\n",
            "downloading.. cna_eng_200810.xml.gz\n",
            "<_io.BufferedWriter name='/content/drive/MyDrive/Colab Notebooks/cna_eng/cna_eng_200810.xml.gz'>\n",
            "downloading.. cna_eng_200812.xml.gz\n",
            "<_io.BufferedWriter name='/content/drive/MyDrive/Colab Notebooks/cna_eng/cna_eng_200812.xml.gz'>\n",
            "downloading.. cna_eng_200902.xml.gz\n",
            "<_io.BufferedWriter name='/content/drive/MyDrive/Colab Notebooks/cna_eng/cna_eng_200902.xml.gz'>\n",
            "downloading.. cna_eng_200904.xml.gz\n",
            "<_io.BufferedWriter name='/content/drive/MyDrive/Colab Notebooks/cna_eng/cna_eng_200904.xml.gz'>\n",
            "downloading.. cna_eng_200906.xml.gz\n",
            "<_io.BufferedWriter name='/content/drive/MyDrive/Colab Notebooks/cna_eng/cna_eng_200906.xml.gz'>\n",
            "downloading.. cna_eng_200908.xml.gz\n",
            "<_io.BufferedWriter name='/content/drive/MyDrive/Colab Notebooks/cna_eng/cna_eng_200908.xml.gz'>\n",
            "downloading.. cna_eng_200910.xml.gz\n",
            "<_io.BufferedWriter name='/content/drive/MyDrive/Colab Notebooks/cna_eng/cna_eng_200910.xml.gz'>\n",
            "downloading.. cna_eng_200912.xml.gz\n",
            "<_io.BufferedWriter name='/content/drive/MyDrive/Colab Notebooks/cna_eng/cna_eng_200912.xml.gz'>\n",
            "downloading.. cna_eng_201002.xml.gz\n",
            "<_io.BufferedWriter name='/content/drive/MyDrive/Colab Notebooks/cna_eng/cna_eng_201002.xml.gz'>\n",
            "downloading.. cna_eng_201004.xml.gz\n",
            "<_io.BufferedWriter name='/content/drive/MyDrive/Colab Notebooks/cna_eng/cna_eng_201004.xml.gz'>\n",
            "downloading.. cna_eng_201006.xml.gz\n",
            "<_io.BufferedWriter name='/content/drive/MyDrive/Colab Notebooks/cna_eng/cna_eng_201006.xml.gz'>\n",
            "downloading.. cna_eng_201008.xml.gz\n",
            "<_io.BufferedWriter name='/content/drive/MyDrive/Colab Notebooks/cna_eng/cna_eng_201008.xml.gz'>\n",
            "downloading.. cna_eng_201010.xml.gz\n",
            "<_io.BufferedWriter name='/content/drive/MyDrive/Colab Notebooks/cna_eng/cna_eng_201010.xml.gz'>\n",
            "downloading.. cna_eng_201012.xml.gz\n",
            "<_io.BufferedWriter name='/content/drive/MyDrive/Colab Notebooks/cna_eng/cna_eng_201012.xml.gz'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZFWfHIClFz9_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "61b87ba2-56cc-4c6f-ffe6-330394872c70"
      },
      "source": [
        "\r\n",
        "extract_content(newdir,extension)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The file does not exist\n",
            "file name cna_eng_199710.xml.gz\n",
            "file name cna_eng_199712.xml.gz\n",
            "file name cna_eng_199802.xml.gz\n",
            "file name cna_eng_199804.xml.gz\n",
            "file name cna_eng_199806.xml.gz\n",
            "file name cna_eng_199808.xml.gz\n",
            "file name cna_eng_199810.xml.gz\n",
            "file name cna_eng_199812.xml.gz\n",
            "file name cna_eng_199902.xml.gz\n",
            "file name cna_eng_199904.xml.gz\n",
            "file name cna_eng_199906.xml.gz\n",
            "file name cna_eng_199908.xml.gz\n",
            "file name cna_eng_199910.xml.gz\n",
            "file name cna_eng_199912.xml.gz\n",
            "file name cna_eng_200002.xml.gz\n",
            "file name cna_eng_200004.xml.gz\n",
            "file name cna_eng_200006.xml.gz\n",
            "file name cna_eng_200008.xml.gz\n",
            "file name cna_eng_200010.xml.gz\n",
            "file name cna_eng_200012.xml.gz\n",
            "file name cna_eng_200102.xml.gz\n",
            "file name cna_eng_200104.xml.gz\n",
            "file name cna_eng_200106.xml.gz\n",
            "file name cna_eng_200108.xml.gz\n",
            "file name cna_eng_200110.xml.gz\n",
            "file name cna_eng_200112.xml.gz\n",
            "file name cna_eng_200202.xml.gz\n",
            "file name cna_eng_200308.xml.gz\n",
            "file name cna_eng_200310.xml.gz\n",
            "file name cna_eng_200312.xml.gz\n",
            "file name cna_eng_200402.xml.gz\n",
            "file name cna_eng_200404.xml.gz\n",
            "file name cna_eng_200406.xml.gz\n",
            "file name cna_eng_200408.xml.gz\n",
            "file name cna_eng_200410.xml.gz\n",
            "file name cna_eng_200412.xml.gz\n",
            "file name cna_eng_200502.xml.gz\n",
            "file name cna_eng_200504.xml.gz\n",
            "file name cna_eng_200506.xml.gz\n",
            "file name cna_eng_200508.xml.gz\n",
            "file name cna_eng_200510.xml.gz\n",
            "file name cna_eng_200512.xml.gz\n",
            "file name cna_eng_200602.xml.gz\n",
            "file name cna_eng_200604.xml.gz\n",
            "file name cna_eng_200606.xml.gz\n",
            "file name cna_eng_200608.xml.gz\n",
            "file name cna_eng_200610.xml.gz\n",
            "file name cna_eng_200612.xml.gz\n",
            "file name cna_eng_200702.xml.gz\n",
            "file name cna_eng_200704.xml.gz\n",
            "file name cna_eng_200706.xml.gz\n",
            "file name cna_eng_200708.xml.gz\n",
            "file name cna_eng_200710.xml.gz\n",
            "file name cna_eng_200712.xml.gz\n",
            "file name cna_eng_200802.xml.gz\n",
            "file name cna_eng_200804.xml.gz\n",
            "file name cna_eng_200806.xml.gz\n",
            "file name cna_eng_200808.xml.gz\n",
            "file name cna_eng_200810.xml.gz\n",
            "file name cna_eng_200812.xml.gz\n",
            "file name cna_eng_200902.xml.gz\n",
            "file name cna_eng_200904.xml.gz\n",
            "file name cna_eng_200906.xml.gz\n",
            "file name cna_eng_200908.xml.gz\n",
            "file name cna_eng_200910.xml.gz\n",
            "file name cna_eng_200912.xml.gz\n",
            "file name cna_eng_201002.xml.gz\n",
            "file name cna_eng_201004.xml.gz\n",
            "file name cna_eng_201006.xml.gz\n",
            "file name cna_eng_201008.xml.gz\n",
            "file name cna_eng_201010.xml.gz\n",
            "file name cna_eng_201012.xml.gz\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CqxJJ6D3qcWH",
        "outputId": "c0e75463-5f93-438d-9e6c-cb5770c8f092"
      },
      "source": [
        "a_file = open(\"/content/deserialized.txt\")\r\n",
        "number_of_lines = 100\r\n",
        "for i in range(number_of_lines):\r\n",
        "    line = a_file.readline()\r\n",
        "    print(line)"
      ],
      "execution_count": 255,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mainland Chinese Foreign Minister Qian Qichen\n",
            "\n",
            "was highly skeptical of Tokyo's explanations of the content of the\n",
            "\n",
            "newly published US-Japan guidelines for defense cooperation when he\n",
            "\n",
            "met Monday in Beijing with representatives of Japan's press.\n",
            "\n",
            "Qian also said the time is not ripe yet for a trilateral official\n",
            "\n",
            "dialogue among Washington, Beijing and Tokyo on defense, adding that\n",
            "\n",
            "\"scholarly discussion\" would be appropriate at the present.\n",
            "\n",
            "Qian's remarks indicate that despite explanations of the new\n",
            "\n",
            "guidelines by Japanese Prime Minister Ryutaro Hashimoto and Foreign\n",
            "\n",
            "Minister Keizo Obuchi, Beijing is still very worried about whether\n",
            "\n",
            "Taiwan falls within the sphere of the bilateral defense agreement.\n",
            "\n",
            "According to reports in the Japanese media, among Qian's concerns\n",
            "\n",
            "are:\n",
            "\n",
            "-- If the defense pact is a matter between Washington and Tokyo,\n",
            "\n",
            "it should be unnecessary to renew it, hence putting its content into\n",
            "\n",
            "doubt.\n",
            "\n",
            "-- Although the new guidelines do not specifically mention\n",
            "\n",
            "geographic criteria, there is still speculation that they cover\n",
            "\n",
            "Taiwan.\n",
            "\n",
            "-- Some have argued for raising the transparency of the bilateral\n",
            "\n",
            "agreement, while others advocate keeping it ambiguous and opaque.\n",
            "\n",
            "The American Chamber of Commerce (AmCham) in\n",
            "\n",
            "Taipei on Wednesday appealed for an early conclusion of trade\n",
            "\n",
            "consultations between the United States and the Republic of China on\n",
            "\n",
            "terms for Taiwan to join the World Trade Organization (WTO).\n",
            "\n",
            "AmCham President Jeffrey R. Williams told a news conference that\n",
            "\n",
            "all AmCham members hope bilateral ROC-US WTO talks will be concluded\n",
            "\n",
            "as soon as possible to facilitate Taiwan's entry to the Geneva-based\n",
            "\n",
            "world trade regulatory body.\n",
            "\n",
            "According to Williams, most American business people with\n",
            "\n",
            "interests in Taiwan are convinced that they will benefit from\n",
            "\n",
            "Taiwan's WTO accession because Taiwan would be required to further\n",
            "\n",
            "open its market and better protect intellectual property rights.\n",
            "\n",
            "Williams, who just returned from a \"doorknocking\" visit to\n",
            "\n",
            "Washington, D.C. at the head of a 12-member AmCham delegation, said\n",
            "\n",
            "the US executive branch agreed with AmCham that Taiwan's WTO\n",
            "\n",
            "accession should not be linked to mainland China's membership\n",
            "\n",
            "application.\n",
            "\n",
            "\"We agree that Taiwan's WTO entry should be considered completely\n",
            "\n",
            "on the basis of its own economic conditions,\" Williams said, adding\n",
            "\n",
            "that Taiwan is likely to conclude WTO-related trade consultations\n",
            "\n",
            "with the United States before the end of bilateral WTO talks between\n",
            "\n",
            "Washington and Beijing.\n",
            "\n",
            "During its stay in the United States, the AmCham delegation met\n",
            "\n",
            "with many Clinton administration officials and Congress members to\n",
            "\n",
            "exchange views on ways to help American corporations upgrade their\n",
            "\n",
            "overseas competitiveness.\n",
            "\n",
            "Williams said the AmCham mission had urged various US federal\n",
            "\n",
            "agencies to allow their senior officials to make frequent visits to\n",
            "\n",
            "Taiwan to help boost bilateral trade and economic cooperation for\n",
            "\n",
            "mutual benefits.\n",
            "\n",
            "Even though the Clinton administration was busy preparing for\n",
            "\n",
            "mainland Chinese President Jiang Zemin's planned visit to the United\n",
            "\n",
            "States late this month, Williams said, many federal government\n",
            "\n",
            "officials still showed keen interest in listening to AmCham's\n",
            "\n",
            "suggestions and opinions about reinforcing Taipei-Washington trade\n",
            "\n",
            "and economic ties.\n",
            "\n",
            "As to the AmCham 1997-98 Taiwan White Paper, which he formally\n",
            "\n",
            "unveiled at a news conference held in Washington, D.C. last Thursday,\n",
            "\n",
            "Williams said the annual report mainly analyzed Taiwan's current\n",
            "\n",
            "economic and investment climate as a reference for American companies\n",
            "\n",
            "intending to invest in Taiwan, adding that the White Paper was not\n",
            "\n",
            "aimed at criticizing any party.\n",
            "\n",
            "The White Paper said Taiwan's restrictions on trade and\n",
            "\n",
            "investment across the Taiwan Strait have not only hindered the\n",
            "\n",
            "development of its own industries but have also discouraged\n",
            "\n",
            "multinational business groups from setting up a foothold on the\n",
            "\n",
            "island. It further claimed that the ROC government's master plan to\n",
            "\n",
            "develop Taiwan into an Asia-Pacific operations center would remain a\n",
            "\n",
            "pipe dream if Taiwan companies are not allowed to enter the vast\n",
            "\n",
            "mainland market directly and obtain access to its resources.\n",
            "\n",
            "Williams said AmCham's analysis was made purely from a commercial\n",
            "\n",
            "viewpoint, adding that AmCham members believe Taiwan must establish\n",
            "\n",
            "direct communications and transport links with mainland China so that\n",
            "\n",
            "Taiwan-based companies can make successful inroads into the world's\n",
            "\n",
            "largest market.\n",
            "\n",
            "Evergreen's green-colored ships and green\n",
            "\n",
            "matchbox-like containers are the hope of the port of Gioia Tauro in\n",
            "\n",
            "southern Italy.\n",
            "\n",
            "Taiwan-based Evergreen Marine Corp., which operates one of the\n",
            "\n",
            "largest container fleets in the world, is wagering on Gioia Tauro, a\n",
            "\n",
            "newly-developed and non-urban port area, attempting to build it into\n",
            "\n",
            "the third largest container port in the world.\n",
            "\n",
            "Evergreen is also targeting Gioia Tauro as a gateway to all\n",
            "\n",
            "Mediterranean-rim states and the Black Sea to the north, said a\n",
            "\n",
            "company spokesman.\n",
            "\n",
            "The Italian government has put up nearly US$180 million since\n",
            "\n",
            "1975 to develop the quiet backwater fishing port into a commercial\n",
            "\n",
            "harbor. With most parts of the development already finished, the\n",
            "\n",
            "harbor accommodated some 1,270 ships in the first six months of this\n",
            "\n",
            "year. The harbor bureau there estimated that its transshipment\n",
            "\n",
            "capacity may reach 1.4 million TEUs this year.\n",
            "\n",
            "Although the port is fully operational, its peripheral facilities\n",
            "\n",
            "are still in dire need of help, Aldo Alessio, mayor of Gioia Tauro,\n",
            "\n",
            "lamented. He noted that many support works have been left unfinished\n",
            "\n",
            "due to budget constraints, with highways in the vicinity only four\n",
            "\n",
            "meters wide and the nearby hinterland remaining undeveloped and\n",
            "\n",
            "blanketed by weeds.\n",
            "\n",
            "Taipei's representative office in Rome, which has generally been\n",
            "\n",
            "reluctant to beckon Taiwan investors to Italy for fear that the\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rDo8aXUeGfmB"
      },
      "source": [
        "**Part 2**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "82CE3iRfSEKm",
        "outputId": "b686cbdc-d130-466f-94fd-edd02df1274d"
      },
      "source": [
        "# Setup\r\n",
        "!pip install -q wordcloud\r\n",
        "import wordcloud\r\n",
        "\r\n",
        "import nltk\r\n",
        "nltk.download('stopwords')\r\n",
        "nltk.download('wordnet')\r\n",
        "nltk.download('punkt')\r\n",
        "nltk.download('averaged_perceptron_tagger') "
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yX62H5c65Tkw"
      },
      "source": [
        "def sentence_tokenization(input_file,output_result):\r\n",
        "    count=0\r\n",
        "    if os.path.exists(output_result):\r\n",
        "        os.remove(output_result)\r\n",
        "    else:\r\n",
        "        print(\"The file does not exist\")\r\n",
        "    with open(input_file,\"r\") as output:\r\n",
        "        text=output.readlines()\r\n",
        "    \r\n",
        "    text_remove_n = [x.replace('\\n','') for x in text]\r\n",
        "    sentences_final=\" \".join(str(x) for x in text_remove_n)\r\n",
        "    upper_case=sentences_final.upper()\r\n",
        "    sent_tokenized = nltk.sent_tokenize(upper_case)\r\n",
        "    for sentence in sent_tokenized:\r\n",
        "      count+=1\r\n",
        "      with open(output_result,\"+a\") as result:\r\n",
        "        result.write(sentence + \"\\n\")\r\n",
        "    print(count)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vBfxsWp7ssIC"
      },
      "source": [
        "**In this part, the function took a file as an input and read it line by line. then the new line characted has been removed and joined the sentences which was coming in multiple line. After that the list is converted into string. Now the file have sentences seperated with period. Then using sentence tokenizer the sentences are separated and saved line by line in a new file. **"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Va2KkzzY5TnV"
      },
      "source": [
        "input_file=\"/content/deserialized.txt\"\r\n",
        "output_result=\"/content/sample_data/Sent_tokenization_result.txt\"\r\n",
        "\r\n"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "o0nJjZRo5Tp-",
        "outputId": "b56045f3-03c2-4486-be07-43c2688660d0"
      },
      "source": [
        "sentence_tokenization(input_file,output_result)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The file does not exist\n",
            "585059\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q_4Ie2c_oYBL"
      },
      "source": [
        "**Total number of sentences in the corpus are 585059**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bDeH6hLCqtHj"
      },
      "source": [
        "**First 100 lines after sentence tokenization**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hN25szZ6p2Vv"
      },
      "source": [
        "a_file = open(\"/content/sample_data/Sent_tokenization_result.txt\")\r\n",
        "number_of_lines = 100\r\n",
        "with open(\"/content/sample_data/first_100_sent_tokenization_result.txt\",\"w\") as output:\r\n",
        "  for i in range(number_of_lines):\r\n",
        "      line = a_file.readline()\r\n",
        "      output.write(line)"
      ],
      "execution_count": 266,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7696iKj_69is"
      },
      "source": [
        "**Word Tokenization**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4-lIorle5Tte"
      },
      "source": [
        "import string\r\n",
        "def word_tokenization(input_file,output_result):\r\n",
        "    if os.path.exists(output_result):\r\n",
        "        os.remove(output_result)\r\n",
        "    else:\r\n",
        "        print(\"The file does not exist\")\r\n",
        "    with open(output_result,\"+a\") as output_text:\r\n",
        "        with open(input_file,\"r\") as input_text:\r\n",
        "            text=input_text.readlines()\r\n",
        "        for line in text:\r\n",
        "            line= line.translate(str.maketrans('','',string.punctuation))\r\n",
        "            word_tokenized = nltk.word_tokenize(line)\r\n",
        "            word_tokens=\" \".join(str(x) for x in word_tokenized)\r\n",
        "            output_text.write(word_tokens+'\\n')"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-POJNYgstPCH"
      },
      "source": [
        "**I have used a modified version for removing puntuations from the entire file and it worked well on inverted commas and doulbe triple quotes.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "9i299N0C5TxB",
        "outputId": "c7351b5d-791c-4813-f18e-04b236b78c7c"
      },
      "source": [
        "\r\n",
        "input_file=\"/content/sample_data/Sent_tokenization_result.txt\"\r\n",
        "output_result=\"/content/sample_data/word_tokenization_result.txt\"\r\n",
        "\r\n",
        "word_tokenization(input_file,output_result)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The file does not exist\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M93QMr6Kqj4P"
      },
      "source": [
        "First 100 lines after word tokenization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lmPakekxqjRn"
      },
      "source": [
        "a_file = open(\"/content/sample_data/word_tokenization_result.txt\")\r\n",
        "number_of_lines = 100\r\n",
        "with open(\"/content/sample_data/first_100_word_tokenization_result.txt\",\"w\") as output:\r\n",
        "  for i in range(number_of_lines):\r\n",
        "      line = a_file.readline()\r\n",
        "      output.write(line)"
      ],
      "execution_count": 265,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qTCmCtLVDoOJ"
      },
      "source": [
        "**PART III**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lA68S2ifDljy"
      },
      "source": [
        "from nltk.util import ngrams\r\n",
        "from collections import Counter\r\n",
        "from nltk.corpus import stopwords"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SuObp_w0_35d"
      },
      "source": [
        "def part_3(input_file, graph_output):\r\n",
        "  with open(input_file,\"r\") as tokens:\r\n",
        "      text=tokens.read()\r\n",
        "\r\n",
        "  word_tokens=nltk.word_tokenize(text)\r\n",
        "  print(\"total word_tokens:\", len(word_tokens))\r\n",
        "\r\n",
        "  ## Part 1:\r\n",
        "  unique_words=list(set(word_tokens))\r\n",
        "  print(\"Part 1:\")\r\n",
        "  print(\"Total unique types:  \",len(unique_words),\"\\n\")\r\n",
        "\r\n",
        "  ## Part 2:\r\n",
        "  val_total=[]\r\n",
        "  unigrams = ngrams(word_tokens,1)\r\n",
        "  c=Counter(unigrams)\r\n",
        "  print(\"Part 2:\")\r\n",
        "  print(\"Total unigram tokens\",len(c),\"\\n\")\r\n",
        "\r\n",
        "  ## Part 3:\r\n",
        "  import numpy as np\r\n",
        "  import matplotlib.pylab as plt\r\n",
        "  frequency={}\r\n",
        "  for x, y in c.items():\r\n",
        "      for key in x:\r\n",
        "          frequency.update({key:y})\r\n",
        "      \r\n",
        "  freq = frequency.values()\r\n",
        "  f = list(freq)\r\n",
        "  f.sort(reverse=True)\r\n",
        "  ranks = range(1, len(f)+1)\r\n",
        "  plt.plot(ranks, f)\r\n",
        "  plt.ylabel('log(frequency)')\r\n",
        "  plt.xlabel('log(rank)')\r\n",
        "  plt.yscale('log')\r\n",
        "  plt.xscale('log')\r\n",
        "  plt.savefig(graph_output)\r\n",
        "\r\n",
        "\r\n",
        "  ## Part 4:\r\n",
        "  print(\"Part 4:\")\r\n",
        "  print(\"The 30 most frequent words are:  \\n\")\r\n",
        "  for val, count in c.most_common(30):\r\n",
        "      for tups in val:\r\n",
        "          print(tups,count)\r\n",
        "          val_total.append(tups)\r\n",
        "          \r\n",
        "  ## Part 5:\r\n",
        "  stop_words = set(stopwords.words('english'))\r\n",
        "  filtered_sentence = []  \r\n",
        "  for w in word_tokens:  \r\n",
        "      lowerword=w.lower()\r\n",
        "      if lowerword not in stop_words:  \r\n",
        "          filtered_sentence.append(w)  \r\n",
        "\r\n",
        "  #print(filtered_sentence) \r\n",
        "\r\n",
        "  ## Part 6\r\n",
        "\r\n",
        "  print(\"\\n Part 5/6:\")\r\n",
        "  print(\"The 30 most frequent words after removing stop words:  \\n\")\r\n",
        "  val_total_remov_stop=[]\r\n",
        "  unigrams_new = ngrams(filtered_sentence,1)\r\n",
        "  c_new=Counter(unigrams_new)\r\n",
        "  for val, count in c_new.most_common(30):\r\n",
        "      for tups in val:\r\n",
        "        print(tups,count)\r\n",
        "        val_total_remov_stop.append(tups)\r\n",
        "\r\n"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1565
        },
        "id": "2hKzLH-u_38C",
        "outputId": "fed1dc20-910d-4069-8822-3549b1e88a34"
      },
      "source": [
        "input_file=\"/content/sample_data/word_tokenization_result.txt\"\r\n",
        "graph_output=\"/content/sample_data/rand_and_freq.png\"\r\n",
        "part_3(input_file,graph_output)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total word_tokens: 16416618\n",
            "Part 1:\n",
            "Total unique types:   138420 \n",
            "\n",
            "Part 2:\n",
            "Total unigram tokens 138420 \n",
            "\n",
            "Part 4:\n",
            "The 30 most frequent words are:  \n",
            "\n",
            "THE 1219252\n",
            "TO 511901\n",
            "OF 505729\n",
            "AND 397237\n",
            "IN 366589\n",
            "A 292772\n",
            "THAT 213959\n",
            "SAID 182444\n",
            "FOR 161746\n",
            "TAIWAN 156616\n",
            "ON 137044\n",
            "WILL 119408\n",
            "WITH 118781\n",
            "IS 113043\n",
            "AT 100494\n",
            "AS 99989\n",
            "BY 98934\n",
            "HE 87063\n",
            "BE 80622\n",
            "FROM 80583\n",
            "HAS 76043\n",
            "WAS 62642\n",
            "CHINA 58284\n",
            "AN 57912\n",
            "PERCENT 56560\n",
            "ITS 55761\n",
            "HAVE 54168\n",
            "NOT 53478\n",
            "IT 52786\n",
            "HIS 52227\n",
            "\n",
            " Part 5/6:\n",
            "The 30 most frequent words after removing stop words:  \n",
            "\n",
            "SAID 182444\n",
            "TAIWAN 156616\n",
            "CHINA 58284\n",
            "PERCENT 56560\n",
            "ALSO 46602\n",
            "TAIWANS 46425\n",
            "CHEN 42420\n",
            "GOVERNMENT 41490\n",
            "PRESIDENT 39952\n",
            "TAIPEI 36700\n",
            "YEAR 36304\n",
            "TWO 33265\n",
            "MAINLAND 32436\n",
            "NEW 31262\n",
            "PEOPLE 29547\n",
            "CHINESE 28906\n",
            "ACCORDING 28557\n",
            "ECONOMIC 26985\n",
            "US 26659\n",
            "PARTY 24495\n",
            "BILLION 24212\n",
            "FIRST 24029\n",
            "NATIONAL 23910\n",
            "ONE 23843\n",
            "FOREIGN 23515\n",
            "WOULD 22702\n",
            "YEARS 22394\n",
            "INTERNATIONAL 21710\n",
            "OFFICIALS 21655\n",
            "LOCAL 21156\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M4OQDVGInTdp"
      },
      "source": [
        "Before removal of stop words, the 30 most frequent word list is more kind of stop words and not meaning ful words. There are few words in english \"stopwords\" collections which are letters rather than words. Also, there are few words which has no meanings in english. We could add other words in the stopwords list but I did not get a chance to work on it due to time limitations."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mEJ1IbrKnSPI"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KVsFFK8Ve4rZ"
      },
      "source": [
        "**PART IV** - Word association metrics\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fQrHN1jJsASh"
      },
      "source": [
        "def total_token_count(ngram_dict):\r\n",
        "    return sum(ngram_dict.values())"
      ],
      "execution_count": 267,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yEl1gKbtjQ4C"
      },
      "source": [
        "def total_type_count(ngram_dict):\r\n",
        "    return len(ngram_dict.values())"
      ],
      "execution_count": 268,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4VugGBZYsAh6"
      },
      "source": [
        "def intdefaultdict():\r\n",
        "    return collections.defaultdict(int)"
      ],
      "execution_count": 269,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NwVk5NFisAk2"
      },
      "source": [
        "def load_object(filename):\r\n",
        "    with open(filename, 'rb') as object_file_stream:\r\n",
        "        return pickle.load(object_file_stream)"
      ],
      "execution_count": 270,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xZ760HPHsAoD"
      },
      "source": [
        "def file_to_unigram_dict(input_file=\"/content/sample_data/word_tokenization_result.txt\",\r\n",
        "                         output_file='/content/sample_data/unigram_count_dict.pkl',):\r\n",
        "\r\n",
        "    unigram_count_dict = collections.defaultdict(int)\r\n",
        "    with open(input_file, 'r') as input_stream:\r\n",
        "        line = input_stream.readline()\r\n",
        "        while line:\r\n",
        "            split_line = line[:-1].split(' ')\r\n",
        "            for token in split_line:\r\n",
        "                unigram_count_dict[token] += 1\r\n",
        "            line = input_stream.readline()\r\n",
        "\r\n",
        "    with open(output_file, 'wb') as output:\r\n",
        "        pickle.dump(unigram_count_dict, output, pickle.HIGHEST_PROTOCOL)"
      ],
      "execution_count": 271,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vczzPRuPrEI6"
      },
      "source": [
        "def file_to_bigram_dict(input_file='/content/sample_data/word_tokenization_result.txt',\r\n",
        "                        output_file='/content/sample_data/bigram_count_dict.pkl'):\r\n",
        "\r\n",
        "    bigram_count_dict = collections.defaultdict(intdefaultdict)\r\n",
        "    with open(input_file, 'r') as input_stream:\r\n",
        "        line = input_stream.readline()\r\n",
        "        while line:\r\n",
        "            split_line = line[:-1].split(' ')\r\n",
        "            for i in range(len(split_line)-1):\r\n",
        "                bigram_count_dict[split_line[i]][split_line[i+1]] += 1\r\n",
        "            line = input_stream.readline()\r\n",
        "\r\n",
        "    with open(output_file, 'wb') as output:\r\n",
        "        pickle.dump(bigram_count_dict, output, pickle.HIGHEST_PROTOCOL)"
      ],
      "execution_count": 272,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rae6bM_irEMM"
      },
      "source": [
        "def unigram_probabilities(ngram_dict, threshold=0):\r\n",
        "    \r\n",
        "    unigram_prob_dict = collections.defaultdict(float)\r\n",
        "    token_count = float(total_token_count(ngram_dict))\r\n",
        "    for token_type in ngram_dict:\r\n",
        "        if ngram_dict[token_type] > threshold:\r\n",
        "            prob = float(ngram_dict[token_type])/token_count\r\n",
        "            unigram_prob_dict[token_type] = prob\r\n",
        "\r\n",
        "    return unigram_prob_dict"
      ],
      "execution_count": 277,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RQ-lPIFcs-K-"
      },
      "source": [
        "def bigram_probabilities(bigram_dict, threshold=0):\r\n",
        "\r\n",
        "    bigram_prob_dict = collections.defaultdict(intdefaultdict)\r\n",
        "    for previous_token in bigram_dict:\r\n",
        "        prev_prob = unigram_probabilities(bigram_dict[previous_token],\r\n",
        "                                              threshold)\r\n",
        "        bigram_prob_dict[previous_token] = prev_prob\r\n",
        "\r\n",
        "    return bigram_prob_dict"
      ],
      "execution_count": 278,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lcodJfxcs-N9"
      },
      "source": [
        "def get_pmi(input_bigram='/content/sample_data/bigram_count_dict.pkl',\r\n",
        "            input_unigram='/content/sample_data/unigram_count_dict.pkl',\r\n",
        "            threshold=0):\r\n",
        "\r\n",
        "\r\n",
        "    bigram_count_dict = load_object(input_bigram)\r\n",
        "    unigram_count_dict = load_object(input_unigram)\r\n",
        "\r\n",
        "    bigram_prob_dict = bigram_probabilities(bigram_count_dict, threshold)\r\n",
        "    unigram_prob_dict = unigram_probabilities(unigram_count_dict)\r\n",
        "\r\n",
        "    pmi_list = list()\r\n",
        "\r\n",
        "    for item in bigram_prob_dict:\r\n",
        "        for token in bigram_prob_dict[item]:\r\n",
        "            pmi = bigram_prob_dict[item][token]/unigram_prob_dict[token]\r\n",
        "            pmi_list.append([pmi, item, token])\r\n",
        "    pmi_list.sort(reverse=True, key=lambda pair: pair[0])\r\n",
        "    return pmi_list"
      ],
      "execution_count": 279,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pi-Gm_BQ6w0M"
      },
      "source": [
        "file_to_unigram_dict()\r\n",
        "file_to_bigram_dict()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZBbXsJkattR1",
        "outputId": "029fa97b-80f7-4dc1-9739-23341eb7d5e4"
      },
      "source": [
        "pmi_list_thresh_0 = get_pmi()\r\n",
        "print(\"30 highest PMI pairs with threshold 0 are: \")\r\n",
        "for index in range(30): print(pmi_list_thresh_0[index])\r\n",
        "\r\n",
        "# With a threshold of 100, what are the 10 highest-PMI word pairs?\r\n",
        "pmi_list_thresh_100 = get_pmi(threshold=100)\r\n",
        "print(\"\\n 10 highest PMI pairs with threshold 100 are: \\n\")\r\n",
        "for index in range(10): print(pmi_list_thresh_100[index])\r\n",
        "\r\n",
        "# Experiment with a few different threshold values, and report on what you observe.\r\n",
        "\r\n",
        "pmi_list_thresh_300 = get_pmi(threshold=300)\r\n",
        "print(\"\\n 10 highest PMI pairs with threshold 300 are: \\n\")\r\n",
        "for index in range(10): print(pmi_list_thresh_300[index])\r\n",
        "\r\n",
        "pmi_list_thresh_1000 = get_pmi(threshold=1000)\r\n",
        "print(\"\\n 10 highest PMI pairs with threshold 1000 are: \\n\")\r\n",
        "for index in range(10): print(pmi_list_thresh_1000[index])\r\n",
        "print(\"\\n PMI for New York: \\n\")\r\n",
        "for pmi_itter in pmi_list_thresh_0:\r\n",
        "\tif pmi_itter[1] == 'NEW' and pmi_itter[2] == 'YORK':\r\n",
        "\t\tprint(pmi_itter)"
      ],
      "execution_count": 276,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "30 highest PMI pairs with threshold 0 are: \n",
            "[16416631.0, 'HANNES', 'FARLEITER']\n",
            "[16416631.0, 'FREIE', 'DEMOKRATISCHE']\n",
            "[16416631.0, 'CEP006', '100397']\n",
            "[16416631.0, 'NICOSIA', 'GORGIE']\n",
            "[16416631.0, 'GORGIE', 'MURADOV']\n",
            "[16416631.0, 'CAUSUS', 'BELLI']\n",
            "[16416631.0, 'HARDCOVER', 'GILTEDGED']\n",
            "[16416631.0, 'US1457', 'US1522']\n",
            "[16416631.0, 'FAYEZ', 'ZAWARNEH']\n",
            "[16416631.0, 'CEP002', '100797']\n",
            "[16416631.0, 'NN1', 'NN2']\n",
            "[16416631.0, 'TULAGA', 'MANUELLA']\n",
            "[16416631.0, 'LUCILLE', 'ROYBALALLARD']\n",
            "[16416631.0, 'HALLDOR', 'ASGRIMSSON']\n",
            "[16416631.0, 'WAHYO', 'DJATMIKO']\n",
            "[16416631.0, 'FLAVONOID', 'SPONIN']\n",
            "[16416631.0, 'ZCCZ', 'CEP007']\n",
            "[16416631.0, 'CEP007', '101097']\n",
            "[16416631.0, 'FRIEDRICH', 'NAUMANN']\n",
            "[16416631.0, 'ANDRIS', 'AMERIKS']\n",
            "[16416631.0, 'GERMANIC', 'MANHOOD']\n",
            "[16416631.0, 'HIMMLERS', 'NUTTY']\n",
            "[16416631.0, 'ZAIMAN', 'NURMATIAS']\n",
            "[16416631.0, 'ESTRADE', 'OYUELA']\n",
            "[16416631.0, 'TOFILAU', 'ETI']\n",
            "[16416631.0, 'STEPAN', 'KERKYASHARIAN']\n",
            "[16416631.0, 'ARY', 'MARDJONO']\n",
            "[16416631.0, 'MESUT', 'YILMAZ']\n",
            "[16416631.0, 'SIXCYLINDER', '68LITER']\n",
            "[16416631.0, 'BACRE', 'WALY']\n",
            "\n",
            " 10 highest PMI pairs with threshold 100 are: \n",
            "\n",
            "[153398.88805031445, 'SPONGIFORM', 'ENCEPHALOPATHY']\n",
            "[151838.8032051282, 'MODUS', 'VIVENDI']\n",
            "[120848.55581761005, 'BOVINE', 'SPONGIFORM']\n",
            "[120362.83529719822, 'ALMA', 'MATER']\n",
            "[109932.796875, 'SRI', 'LANKA']\n",
            "[86770.30070788108, 'BLACKFACED', 'SPOONBILLS']\n",
            "[79291.91925647655, 'KUALA', 'LUMPUR']\n",
            "[76706.4015218939, 'QIAN', 'QICHEN']\n",
            "[74566.38256410256, 'SAO', 'TOME']\n",
            "[69702.46683581008, 'AU', 'OPTRONICS']\n",
            "\n",
            " 10 highest PMI pairs with threshold 300 are: \n",
            "\n",
            "[41738.34774969683, 'BURKINA', 'FASO']\n",
            "[38550.93709638842, 'MAD', 'COW']\n",
            "[34070.27506385696, 'NAUTICAL', 'MILES']\n",
            "[30122.82386116323, 'POUND', 'STERLING']\n",
            "[27259.77165861514, 'HON', 'HAI']\n",
            "[25603.43856823266, 'FALUN', 'GONG']\n",
            "[22229.481236673775, 'SWEDEN', 'KRONE']\n",
            "[21665.549543444144, 'DALAI', 'LAMA']\n",
            "[20088.546430732, 'COSTA', 'RICA']\n",
            "[17811.42771191289, 'CLOUD', 'GATE']\n",
            "\n",
            " 10 highest PMI pairs with threshold 1000 are: \n",
            "\n",
            "[11844.164700561565, 'ACADEMIA', 'SINICA']\n",
            "[4951.20469317968, 'STATUS', 'QUO']\n",
            "[4668.343264510941, 'KEY', 'BAROMETER']\n",
            "[4316.622711921648, 'SOLIDARITY', 'UNION']\n",
            "[4094.8842587323657, 'VINCENT', 'SIEW']\n",
            "[3922.980486932028, 'REFERENCE', 'LEVELS']\n",
            "[3788.4270090432765, 'REMAINING', 'UNCHANGED']\n",
            "[3630.409857494104, 'TYPHOON', 'MORAKOT']\n",
            "[3507.542485549221, 'PANBLUE', 'ALLIANCE']\n",
            "[3046.2218898305405, 'JAMES', 'SOONG']\n",
            "\n",
            " PMI for New York: \n",
            "\n",
            "[519.3311010715668, 'NEW', 'YORK']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XcKsh6v88AMD"
      },
      "source": [
        "**The PMI for \"New York\" is comparatively very low. In my understanding the conditional probabily is low since the word \"NEW\" is very common with any other word other then \"YORK\". \"NEW\" can pair frequently with other words also.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2hC1sy47IkEB"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HueemROVVAbv"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2g7i6cZkVAek"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s3nKAltfVAhE"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}